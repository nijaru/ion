{
  "project": "tk",
  "ref": "vo8l",
  "title": "[EVAL] Evaluate and iterate on system prompt",
  "description": "Review and improve the system prompt for quality, clarity, and effectiveness. Compare with competitive agents (Claude Code, Gemini CLI, opencode). Consider: instruction format, tool descriptions, behavior guidance, tone/personality directives.",
  "status": "open",
  "priority": 3,
  "labels": [],
  "assignees": [],
  "parent": null,
  "blocked_by": [],
  "estimate": null,
  "due_date": null,
  "logs": [
    {
      "ts": "2026-02-14T08:22:01.982Z",
      "msg": "User wants system prompt and tool architecture bumped to higher priority — should be next after MCP migration"
    },
    {
      "ts": "2026-02-14T12:37:06.529Z",
      "msg": "Applied effectiveness analysis recommendations: 662→436 words (34% reduction). Cut model-default instructions (respect conventions, fix root causes, write clean code), condensed tool routing to 1 line, removed Output section redundancies. Kept all load-bearing instructions (persistence, read-before-edit, parallel calls, no ANSI, safety). Researcher still running on competitor survey."
    },
    {
      "ts": "2026-02-14T12:38:30.722Z",
      "msg": "Added anti-over-engineering line from competitor survey. Researcher wrote comprehensive 486-line survey of 5 agents (Claude Code, Gemini CLI, OpenCode, Codex CLI, Amp) to ai/research/system-prompt-survey-2026-02.md. Additional patterns identified for future iteration: guardrails section (simple-first, reuse-first), fast context understanding, plan quality examples, question policy."
    },
    {
      "ts": "2026-02-14T21:15:27.532Z",
      "msg": "Research complete. Key findings: gpt-5.3-codex trained on Responses API (local_shell, freeform apply_patch), not Chat Completions. Ion uses Chat Completions with standard function tools — format mismatch is structural gap. Quick wins: structured tool results, stronger autonomy language, smarter truncation. See ai/research/codex-cli-system-prompt-tools-2026.md"
    },
    {
      "ts": "2026-02-14T22:01:37.741Z",
      "msg": "Second iteration complete. Added guardrails (simple-first, reuse-first), strengthened autonomy, structured bash output, question policy. Remaining value is in model-specific prompts (code change, part of tk-gkrr) and token-based truncation, not more prompt text."
    },
    {
      "ts": "2026-02-14T22:32:41.418Z",
      "msg": "Next iteration: model-specific prompt selection (GPT-5 vs Claude vs Gemini get different instructions), token-based tool output truncation (10k tokens vs current 100KB bytes), no-flattery line, fast-context-understanding pattern. Tie prompt selection into tk-gkrr (Responses API) since GPT-5.x needs the most different prompt."
    }
  ],
  "created_at": "2026-02-14T04:56:19.106Z",
  "updated_at": "2026-02-14T22:32:41.418Z",
  "completed_at": null,
  "external": {}
}